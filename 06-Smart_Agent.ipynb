{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6423f8f3-a592-4ee7-9969-39e38933be52",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bf854d-94d7-4a65-952a-22c7999a9a9b",
   "metadata": {},
   "source": [
    "So far we have done the following on the prior Notebooks:\n",
    "\n",
    "- **Notebook 01**: We loaded the Azure Search Engine with enriched PDFs in index: \"cogsrch-index-files\"\n",
    "- **Notebook 02**: We added AzureOpenAI GPT models to enhance the the production of the answer by using Utility Chains of LLMs\n",
    "- **Notebook 03**: We manually loaded an index with large/complex PDFs information , \"cogsrch-index-books\"\n",
    "- **Notebook 04**: We added memory to our system in order to power a conversational Chat Bot\n",
    "- **Notebook 05**: We introduced Agents and Tools and built the first Skill/Agent, that can do RAG over a search engine\n",
    "\n",
    "We are missing one more thing: **How do we glue all these features together into a very smart GPT Smart Search Engine Chat Bot?**\n",
    "\n",
    "We want a virtual assistant for our company that can get the question, think what tool to use, then get the answer. The goal is that, regardless of the source of the information (Search Engine, Bing Search, SQL Database, CSV File, JSON File, APIs, etc), the Assistant can answer the question correctly using the right tool.<br>\n",
    "â€» We can build more tools the agent will use.\n",
    "\n",
    "In this Notebook we are going to create that \"brain\" Agent (also called Master Agent), that:\n",
    "\n",
    "1) understands the question, interacts with the user \n",
    "2) talks to other specialized Agents that are connected to diferent sources\n",
    "3) once it get's the answer it delivers it to the user or let the specialized Agent to deliver it directly\n",
    "\n",
    "This is the same concept of [AutoGen](https://www.microsoft.com/en-us/research/blog/autogen-enabling-next-generation-large-language-model-applications/): Agents talking to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7fa9dc-64cb-4ee2-ae98-8cdb72293cbe",
   "metadata": {},
   "source": [
    "![image](./images/AutoGen_Fig1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b81551-92ac-4f08-9c00-ba11981c67c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import requests\n",
    "from operator import itemgetter\n",
    "from typing import Union, List\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.agents import AgentExecutor, Tool, create_openai_tools_agent\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory, CosmosDBChatMessageHistory\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.runnables import ConfigurableFieldSpec, ConfigurableField\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.output_parsers import JsonOutputToolsParser\n",
    "from langchain_core.runnables import (\n",
    "    Runnable,\n",
    "    RunnableLambda,\n",
    "    RunnableMap,\n",
    "    RunnablePassthrough,\n",
    ")\n",
    "\n",
    "#custom libraries that we will use later in the app\n",
    "from common.utils import (\n",
    "    DocSearchAgent, \n",
    "    CSVTabularAgent, \n",
    "    SQLSearchAgent, \n",
    "    ChatGPTTool, \n",
    "    BingSearchAgent, \n",
    "    APISearchAgent, \n",
    "    reduce_openapi_spec\n",
    ")\n",
    "from common.callbacks import StdOutCallbackHandler\n",
    "from common.prompts import CUSTOM_CHATBOT_PROMPT \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"credentials.env\")\n",
    "\n",
    "from IPython.display import Markdown, HTML, display \n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cd1e3e-8527-4a8f-ba90-e700ae7b20ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b56a94-0471-41c3-b441-3a73ff5dedfc",
   "metadata": {},
   "source": [
    "### Get the Tool - DocSearch Agent, ChatGPT (more agents can be included - CSV Agent, SQL Agent, Web Search Agent, ChatGPT, API Agent)\n",
    "\n",
    "**Consider the following concept:** Agents, which are essentially software entities designed to perform specific tasks, can be equipped with tools. These tools themselves can be other agents, each possessing their own set of tools. This creates a layered structure where tools can range from code sequences to human actions, forming interconnected chains. Ultimately, you're constructing a network of agents and their respective tools, all collaboratively working towards solving a specific task (This is what ChatGPT is). This network operates by leveraging the unique capabilities of each agent and tool, creating a dynamic and efficient system for task resolution.\n",
    "\n",
    "In the file `common/utils.py` we created Agent Tools Classes for each of the Functionalities that we developed in prior Notebooks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643d1650-6416-46fd-8b21-f5fb298ec063",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_handler = StdOutCallbackHandler()\n",
    "cb_manager = CallbackManager(handlers=[cb_handler])\n",
    "\n",
    "COMPLETION_TOKENS = 2000\n",
    "\n",
    "# We can run the everything with GPT3.5, but try also GPT4 and see the difference in the quality of responses\n",
    "# You will notice that GPT3.5 is not as reliable.\n",
    "\n",
    "llm = AzureChatOpenAI(deployment_name=os.environ[\"GPT35_DEPLOYMENT_NAME\"], \n",
    "                      temperature=0, max_tokens=COMPLETION_TOKENS)\n",
    "\n",
    "# Uncomment below if you want to see the answers streaming\n",
    "# llm = AzureChatOpenAI(deployment_name=os.environ[\"GPT35_DEPLOYMENT_NAME\"], temperature=0.5, max_tokens=COMPLETION_TOKENS, streaming=True, callback_manager=cb_manager)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a4cc93-2dd6-45eb-ac5b-5af2d31809dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_indexes = [\"cogsrch-index-files\"]\n",
    "doc_search = DocSearchAgent(llm=llm, indexes=doc_indexes,\n",
    "                           k=6, reranker_th=1,\n",
    "                           sas_token=os.environ['BLOB_SAS_TOKEN'],\n",
    "                           name=\"docsearch\",\n",
    "                           description=\"useful when the questions includes the term: docsearch\",\n",
    "                           callback_manager=cb_manager, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafd5bf5-28ee-4edd-978b-384cce057257",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_indexes = [\"cogsrch-index-books\"]\n",
    "book_search = DocSearchAgent(llm=llm, indexes=book_indexes,\n",
    "                           k=5, reranker_th=1,\n",
    "                           sas_token=os.environ['BLOB_SAS_TOKEN'],\n",
    "                           name=\"booksearch\",\n",
    "                           description=\"useful when the questions includes the term: booksearch\",\n",
    "                           callback_manager=cb_manager, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65465173-92f6-489d-9b48-58d109c5723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ChatGPTTool is a custom Tool class created to talk to ChatGPT knowledge\n",
    "chatgpt_search = ChatGPTTool(llm=llm, callback_manager=cb_manager,\n",
    "                             name=\"chatgpt\",\n",
    "                            description=\"use for general questions, profile, greeting-like questions and when the questions includes the term: chatgpt\",\n",
    "                            verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179fc56a-b7e4-44a1-8b7f-68b2b4d02e13",
   "metadata": {},
   "source": [
    "### Variables/knobs to use for customization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f11831-7578-4326-b3b3-d9b073a7149d",
   "metadata": {},
   "source": [
    "As you have seen so far, there are many knobs that you can dial up or down in order to change the behavior of your GPT Smart Search engine application, these are the variables you can tune:\n",
    "\n",
    "- <u>llm</u>:\n",
    "  - **deployment_name**: this is the deployment name of your Azure OpenAI model. This of course dictates the level of reasoning and the amount of tokens available for the conversation. For a production system you will need gpt-4-32k. This is the model that will give you enough reasoning power to work with agents, and enough tokens to work with detailed answers and conversation memory.\n",
    "  - **temperature**: How creative you want your responses to be\n",
    "  - **max_tokens**: How long you want your responses to be. It is recommended a minimum of 500\n",
    "- <u>Tools</u>: To each tool you can add the following parameters to modify the defaults (set in utils.py), these are very important since they are part of the system prompt and determines what tool to use and when.\n",
    "  - **name**: the name of the tool\n",
    "  - **description**: when the brain agent should use this tool\n",
    "- <u>DocSearchAgent</u>: \n",
    "  - **k**: The top k results per index from the text search action\n",
    "  - **similarity_k**: top k results combined from the vector search action\n",
    "  - **reranker_th**: threshold of the semantic search reranker. Picks results that are above the threshold. Max possible score=4\n",
    "  \n",
    "in `utils.py` you can also tune:\n",
    "- <u>model_tokens_limit</u>: In this function you can edit what is the maximum allows of tokens reserve for the content. Remember that the remaining will be for the system prompt plus the answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ee1058-debb-4f97-92a4-999e0c4e0386",
   "metadata": {},
   "source": [
    "### Test the Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473222f1-b423-49f3-98e7-ab70dcf47bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Document Search Tool with a question that we know it has the answer for\n",
    "printmd(doc_search.run(\"what is the responsibility of Manager of Human Resources?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a5ed66-e7ff-43bd-829f-c028476d2593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the other index created manually\n",
    "printmd(book_search.run(\"Can I move, backup, and restore indexes?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70501c2-03d0-4072-b451-ddb92f4add56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the ChatGPTWrapper Search Tool\n",
    "printmd(chatgpt_search.run(\"what is the function in python that allows me to get a random number?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0ff658-b75a-4960-8576-65472844ad05",
   "metadata": {},
   "source": [
    "### Define what tools are we going to give to our brain agent\n",
    "\n",
    "Go to `common/utils.py` to check the tools definition and the instructions on what tool to use when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d018c884-5c91-4a35-90e3-6a5a6e510c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [doc_search, book_search, chatgpt_search]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27699991-00d8-4f0a-8511-e03e530910c3",
   "metadata": {},
   "source": [
    "# Option 1: Using OpenAI functions as router"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aed5eb-846d-44d1-acf1-04b8ff931d30",
   "metadata": {},
   "source": [
    "We need a method to route the question to the right tool, one way to do this is to use OpenAI models functions via the Tools API (models 1106 and newer). To do this, we need to bind these tools/functions to the model and let the model respond with the right tool to use.\n",
    "\n",
    "The advantage of this option is that there is no another agent in the middle between the experts (agent tools) and the user. Each agent tool responds directly. Also, another advantage is that multiple tools can be called in parallel.\n",
    "\n",
    "**Note**: on this method it is important that each agent tool has the same system profile prompt so they adhere to the same reponse guidelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218163af-2279-4891-8699-7f9f291c49f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)\n",
    "tool_map = {tool.name: tool for tool in tools}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5e8efd-b907-4157-99f8-15a44a63f17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_tool(tool_invocation: dict) -> Union[str, Runnable]:\n",
    "    \"\"\"Function for dynamically constructing the end of the chain based on the model-selected tool.\"\"\"\n",
    "    tool = tool_map[tool_invocation[\"type\"]]\n",
    "    return RunnablePassthrough.assign(output=itemgetter(\"args\") | tool)\n",
    "\n",
    "def print_response(result: List):\n",
    "    for answer in result:\n",
    "        printmd(\"**\"+answer[\"type\"] + \"**\" + \": \" + answer[\"output\"])\n",
    "        printmd(\"----\")\n",
    "      \n",
    "# .map() allows us to apply a function to a list of inputs.\n",
    "call_tool_list = RunnableLambda(call_tool).map()\n",
    "agent = llm_with_tools | JsonOutputToolsParser() | call_tool_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec71da3f-097b-4b56-bfcb-c5ed241d8cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke(\"hi, how are you, what is your name?\")\n",
    "print_response(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63682613-daa3-49fa-9fe0-6e5af8ff05ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke(\"Who is the current president of France?\")\n",
    "print_response(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f58b57b-51cb-433c-b6a8-376e6aa06e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke(\"docsearch,chatgpt, what is the responsibility of Manager of Human Resources?\")\n",
    "print_response(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb036da4-825f-45a4-a08f-c5a272c8f895",
   "metadata": {},
   "source": [
    "# Option 2: Using a user facing agent that calls the agent tools experts\n",
    "\n",
    "With this method, we create a user facing agent that talks to the user and also talks to the experts (agent tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc02389-cf52-4a5f-b4a1-2820ee5d8116",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Initialize the brain agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea67e969-26b3-4e6f-a6c0-16780ed418e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_openai_tools_agent(llm, tools, CUSTOM_CHATBOT_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d2d5b4-0145-402e-a620-0fe3f3548acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ffef69-5dcd-423a-802d-7a0c419c7e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id: str, user_id: str) -> CosmosDBChatMessageHistory:\n",
    "    cosmos = CosmosDBChatMessageHistory(\n",
    "        cosmos_endpoint=os.environ['AZURE_COSMOSDB_ENDPOINT'],\n",
    "        cosmos_database=os.environ['AZURE_COSMOSDB_NAME'],\n",
    "        cosmos_container=os.environ['AZURE_COSMOSDB_CONTAINER_NAME'],\n",
    "        connection_string=os.environ['AZURE_COMOSDB_CONNECTION_STRING'],\n",
    "        session_id=session_id,\n",
    "        user_id=user_id\n",
    "        )\n",
    "\n",
    "    # prepare the cosmosdb instance\n",
    "    cosmos.prepare_cosmos()\n",
    "    return cosmos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e389f9-17cc-4c12-80e0-ab671b46bf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_agent_executor = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\",\n",
    "    history_factory_config=[\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"user_id\",\n",
    "            annotation=str,\n",
    "            name=\"User ID\",\n",
    "            description=\"Unique identifier for the user.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"session_id\",\n",
    "            annotation=str,\n",
    "            name=\"Session ID\",\n",
    "            description=\"Unique identifier for the conversation.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601fce84-4a02-41a6-8ae2-f692174d4cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where we configure the session id and user id\n",
    "random_session_id = \"session\"+ str(random.randint(1, 1000))\n",
    "ramdom_user_id = \"user\"+ str(random.randint(1, 1000))\n",
    "\n",
    "config={\"configurable\": {\"session_id\": random_session_id, \"user_id\": ramdom_user_id}}\n",
    "print(random_session_id, ramdom_user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4904a07d-b857-45d7-86ac-c7cade3e9080",
   "metadata": {},
   "source": [
    "### Let's talk to our GPT Smart Search Engine chat bot now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b37988b-9fb4-4958-bc17-d58d8dac8bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This question should not use any tool, the brain agent should answer it without the use of any tool\n",
    "printmd(brain_agent_executor.invoke({\"question\": \"Hi, I'm Pablo Marin, how are you doing today?\"}, config=config)[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a070c558-3963-40ef-b94e-365324ee3d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "printmd(brain_agent_executor.invoke({\"question\": \"what is your name and what do you do?\"}, config=config)[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdc3ad9-ad59-4135-87f6-e86728a11b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "printmd(brain_agent_executor.invoke({\"question\": \"booksearch, Can I move indexes?\"}, \n",
    "                                    config=config)[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0b33f9-75fa-4a3e-b9d8-8fd30dbfd3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "printmd(brain_agent_executor.invoke({\"question\": \"chatgpt, tell me the formula in physics for momentum\"}, config=config)[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f354eb-884d-4fd3-842e-a8adc3b09a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "printmd(brain_agent_executor.invoke({\"question\": \"docsearch, what is the responsibility of Manager of Human Resources?\"}, config=config)[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ded8d9-0bfe-4e16-be3f-382271c120a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "printmd(brain_agent_executor.invoke({\"question\": \"Thank you Jarvis!\"}, config=config)[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8baf56e",
   "metadata": {},
   "source": [
    "### Let's talk to our GPT Smart Search Engine chat bot with more questions and validate the responses from the chat bot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a54fc7-ec9b-4ced-9e17-c65d00aa97f6",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c48d899-bd7b-4081-a656-e8d9e597220d",
   "metadata": {},
   "source": [
    "Great!, We just built the GPT Smart Search Engine!\n",
    "In this Notebook we created the brain, the decision making Agent that decides what Tool to use to answer the question from the user. This is what was necessary in order to have an smart chat bot.\n",
    "\n",
    "We can have many tools to accomplish different tasks, including connecting to APIs, dealing with File Systems, and even using Humans as Tools. For more reference see [HERE](https://python.langchain.com/docs/integrations/tools/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9969ed7e-3680-4853-b750-675a42d3b9ea",
   "metadata": {},
   "source": [
    "# NEXT\n",
    "It is time now to use all the functions and prompts build so far and build a Web application.\n",
    "The Next notebook will guide you on how to build:\n",
    "\n",
    "1) A Bot API Backend\n",
    "2) A Frontend UI with a Search and Webchat interfaces"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
