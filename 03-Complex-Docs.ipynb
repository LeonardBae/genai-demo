{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# How to deal with complex/large Documents"
      ],
      "metadata": {},
      "id": "60ec6048-44e4-4118-b16a-9c4c9cc78a3b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous notebook, we developed a solution for various types of files and data formats commonly found in organizations, and this covers big majority of the use cases. However, you will find that there are issues when dealing with questions that require answers from complex files. The complexity of these files arises from their length and the way information is distributed within them. Large documents are always a challenge for Search Engines.\n",
        "\n",
        "One example of such complex files is Technical Specification Guides or Product Manuals, which can span hundreds of pages and contain information in the form of images, tables, forms, and more. Books are also complex due to their length and the presence of images or tables.\n",
        "\n",
        "These files are typically in PDF format. To better handle these PDFs, we need a smarter parsing method that treats each document as a special source and processes them page by page (1 page = 1 chunk). The objective is to obtain more accurate and faster answers from our system. Fortunately, there are usually not many of these types of documents in an organization, allowing us to make exceptions and treat them differently.\n",
        "\n",
        "If your use case is just PDFs, for example, you can just use [PyPDF library](https://pypi.org/project/pypdf/) or [Azure AI Document Intelligence SDK (former Form Recognizer)](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/overview?view=doc-intel-3.0.0), vectorize using OpenAI API and push the content to a vector-based index. And this is problably the simplest and fastest way to go.  However if your use case entails connecting to a datalake, or Sharepoint libraries or any other document data source with thousands of documents with multiple file types and that can change dynamically, then you would want to use the Ingestion and Document Cracking and AI-Enrichment capabilities of Azure Search engine, Notebooks 1-2, and avoid a lot of painful custom code. \n"
      ],
      "metadata": {},
      "id": "9281ac79-47cd-49d4-bdd4-7f5c173a947d"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import requests\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "import urllib.request\n",
        "from tqdm import tqdm\n",
        "from typing import List\n",
        "\n",
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_core.retrievers import BaseRetriever\n",
        "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_core.runnables import ConfigurableField\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from operator import itemgetter\n",
        "\n",
        "\n",
        "from common.utils import parse_pdf, read_pdf_files, text_to_base64\n",
        "from common.prompts import DOCSEARCH_PROMPT\n",
        "from common.utils import CustomAzureSearchRetriever\n",
        "\n",
        "\n",
        "from IPython.display import Markdown, HTML, display  \n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "def printmd(string):\n",
        "    display(Markdown(string))\n",
        "    \n",
        "os.makedirs(\"data/books/\",exist_ok=True)\n",
        " \n",
        "BLOB_CONTAINER_NAME = \"books\"\n",
        "\n",
        "c = os.environ[\"BLOB_CONNECTION_STRING\"].split(\";\")\n",
        "BASE_CONTAINER_URL = c[0].split(\"=\")[1] + BLOB_CONTAINER_NAME + \"/\"\n",
        "\n",
        "LOCAL_FOLDER = \"./data/books/\"\n",
        "\n",
        "os.makedirs(LOCAL_FOLDER,exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1713768375401
        }
      },
      "id": "15f6044e-463f-4988-bc46-a3c3d641c15c"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1713768377206
        }
      },
      "id": "331692ba-b68e-4b99-9bae-5057da9a389d"
    },
    {
      "cell_type": "code",
      "source": [
        "embedder = AzureOpenAIEmbeddings(deployment=os.environ[\"EMBEDDING_DEPLOYMENT_NAME\"], chunk_size=1) "
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1713768378787
        }
      },
      "id": "594ff0d4-56e3-4bed-843d-28c7a092069b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 - Manual Document Cracking with Push to Vector-based Index"
      ],
      "metadata": {},
      "id": "bb87c647-158c-4f85-b569-5b9462f06c83"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Within our demo storage account, we have a container named `books`, which holds 5 books of different lengths, languages, and complexities. Let's create a `cogsrch-index-books-vector` and load it with the pages of all these books.\n",
        "\n",
        "We begin by downloading these books to our local machine:"
      ],
      "metadata": {},
      "id": "75551868-1546-421b-a14e-e42618d88e61"
    },
    {
      "cell_type": "code",
      "source": [
        "# books = [\"Azure_Cognitive_Search_Documentation.pdf\", \n",
        "#          \"Boundaries_When_to_Say_Yes_How_to_Say_No_to_Take_Control_of_Your_Life.pdf\",\n",
        "#          \"Fundamentals_of_Physics_Textbook.pdf\",\n",
        "#          \"Made_To_Stick.pdf\",\n",
        "#          \"Pere_Riche_Pere_Pauvre.pdf\"]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713623702054
        }
      },
      "id": "0999e24b-6a75-4fa1-9a5f-426cf0f0bdba"
    },
    {
      "cell_type": "code",
      "source": [
        "books = [\"azure-ai-studio.pdf\", \"azure-ai-services.pdf\"]"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1713768382219
        }
      },
      "id": "65ff5fcc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's download the files to the local `./data/` folder:"
      ],
      "metadata": {},
      "id": "dd867b2f-b5a1-443c-aa0a-ce914a66b3c9"
    },
    {
      "cell_type": "code",
      "source": [
        "for book in tqdm(books):\n",
        "    book_url = BASE_CONTAINER_URL + book + os.environ['BLOB_SAS_TOKEN']\n",
        "    urllib.request.urlretrieve(book_url, LOCAL_FOLDER+ book)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\r  0%|          | 0/2 [00:00<?, ?it/s]\r  0%|          | 0/2 [00:00<?, ?it/s]\n"
        },
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "HTTP Error 404: The specified blob does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m book \u001b[38;5;129;01min\u001b[39;00m tqdm(books):\n\u001b[1;32m      2\u001b[0m     book_url \u001b[38;5;241m=\u001b[39m BASE_CONTAINER_URL \u001b[38;5;241m+\u001b[39m book \u001b[38;5;241m+\u001b[39m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBLOB_SAS_TOKEN\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m     \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbook_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLOCAL_FOLDER\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbook\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/urllib/request.py:241\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    239\u001b[0m url_type, path \u001b[38;5;241m=\u001b[39m _splittype(url)\n\u001b[0;32m--> 241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mclosing(\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m    242\u001b[0m     headers \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39minfo()\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;66;03m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/urllib/request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: The specified blob does not exist."
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1713768386435
        }
      },
      "id": "3554f0b7-fee8-4446-a155-5d22dc0f0888"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What to use: pyPDF or AI Documment Intelligence API (Form Recognizer)?\n",
        "\n",
        "In `utils.py` there is a **parse_pdf()** function. This utility function can parse local files using PyPDF library and can also parse local or from_url PDFs files using Azure AI Document Intelligence (Former Form Recognizer).\n",
        "\n",
        "If `form_recognizer=False`, the function will parse the PDF using the python pyPDF library, which 75% of the time does a good job.<br>\n",
        "\n",
        "Setting `form_recognizer=True`, is the best (and slower) parsing method using AI Documment Intelligence API (former known as Form Recognizer). You can specify the prebuilt model to use, the default is `model=\"prebuilt-document\"`. However, if you have a complex document with tables, charts and figures , you can try\n",
        "`model=\"prebuilt-layout\"`, and it will capture all of the nuances of each page (it takes longer of course).\n",
        "\n",
        "**Note: Many PDFs are scanned images. For example, any signed contract that was scanned and saved as PDF will NOT be parsed by pyPDF. Only AI Documment Intelligence API will work.**"
      ],
      "metadata": {},
      "id": "788cc0db-9dae-45f2-8943-2b6fa32fcc75"
    },
    {
      "cell_type": "code",
      "source": [
        "book_pages_map = dict()\n",
        "for book in books:\n",
        "    print(\"Extracting Text from\",book,\"...\")\n",
        "    \n",
        "    # Capture the start time\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Parse the PDF\n",
        "    book_path = LOCAL_FOLDER+book\n",
        "    book_map = parse_pdf(file=book_path, form_recognizer=True, verbose=True)\n",
        "    book_pages_map[book]= book_map\n",
        "    \n",
        "    # Capture the end time and Calculate the elapsed time\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "\n",
        "    print(f\"Parsing took: {elapsed_time:.6f} seconds\")\n",
        "    print(f\"{book} contained {len(book_map)} pages\\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Extracting Text from azure-ai-studio.pdf ...\nExtracting text using Azure Document Intelligence\nParsing took: 178.611562 seconds\nazure-ai-studio.pdf contained 654 pages\n\nExtracting Text from azure-ai-services.pdf ...\nExtracting text using Azure Document Intelligence\nParsing took: 64.384216 seconds\nazure-ai-services.pdf contained 290 pages\n\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1713768671655
        }
      },
      "id": "c1c63a2f-7a53-4346-8a1f-483cfd159d34"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's check a random page of each book to make sure the parsing was done correctly:"
      ],
      "metadata": {},
      "id": "5de0a722-ae0c-4b57-802a-518f5d4d93fd"
    },
    {
      "cell_type": "code",
      "source": [
        "for bookname,bookmap in book_pages_map.items():\n",
        "    print(bookname,\"\\n\",\"chunk text:\",bookmap[random.randint(10, 50)][2][:120],\"...\\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "azure-ai-studio.pdf \n chunk text: 1. 아직 플레이그라운드에 있지 않다면 상단 메뉴에서 빌드를 선택한 다음 축소 가능 한 왼쪽 메뉴에서 플레이그라운드를 선택합니다.\n2. 도우미 설정 창에서 데이터 추가(미리 보기)>+ 데이터 원본 추가를 선택합니다. ...\n\nazure-ai-services.pdf \n chunk text: Azure AI서비스에대한사용자지정하위 도메인 이름\n아티클 • 2024. 02. 29.\n2019년 7월부터 Azure AI 서비스는 Azure Portal , Azure Cloud Shell 또는 Azure CLI를 ...\n\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1713769507804
        }
      },
      "id": "f2a5d62f-b664-4662-a6c9-a1eb2a3c5e11"
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see above, all books were parsed except `Pere_Riche_Pere_Pauvre.pdf` (this book is \"Rich Dad, Poor Dad\" written in French), why? Well, as we mentioned above, this book was scanned, so each page is an image and with a very unique font. We need a good PDF parser with good OCR capabilities in order to extract the content of this PDF. \n",
        "Let's try to parse this book again, but this time using Azure Document Intelligence API (former Form Recognizer)"
      ],
      "metadata": {},
      "id": "8bcdc1ee-71fc-49d2-8e7c-0964bc3a4370"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "book = \"azure-ai-services-openai.pdf\"\n",
        "book_path = LOCAL_FOLDER+book\n",
        "book_map = parse_pdf(file=book_path, form_recognizer=True, model=\"prebuilt-document\",from_url=False, verbose=True)\n",
        "book_pages_map[book]= book_map"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Extracting text using Azure Document Intelligence\n"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "File \u001b[0;32m<timed exec>:3\u001b[0m\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/cjh2201/code/Users/cjh220/Azure-AI-Search-Azure-OpenAI-Workbench/common/utils.py:120\u001b[0m, in \u001b[0;36mparse_pdf\u001b[0;34m(file, form_recognizer, formrecognizer_endpoint, formrecognizerkey, model, from_url, verbose)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     poller \u001b[38;5;241m=\u001b[39m form_recognizer_client\u001b[38;5;241m.\u001b[39mbegin_analyze_document_from_url(model, document_url \u001b[38;5;241m=\u001b[39m file)\n\u001b[0;32m--> 120\u001b[0m form_recognizer_results \u001b[38;5;241m=\u001b[39m \u001b[43mpoller\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page_num, page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(form_recognizer_results\u001b[38;5;241m.\u001b[39mpages):\n\u001b[1;32m    123\u001b[0m     tables_on_page \u001b[38;5;241m=\u001b[39m [table \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m form_recognizer_results\u001b[38;5;241m.\u001b[39mtables \u001b[38;5;28;01mif\u001b[39;00m table\u001b[38;5;241m.\u001b[39mbounding_regions[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpage_number \u001b[38;5;241m==\u001b[39m page_num \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/polling/_poller.py:230\u001b[0m, in \u001b[0;36mLROPoller.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PollingReturnType:\n\u001b[1;32m    223\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the result of the long running operation, or\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m    the result available after the specified timeout.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m    :raises ~azure.core.exceptions.HttpResponseError: Server problem with the query.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 230\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_polling_method\u001b[38;5;241m.\u001b[39mresource()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/tracing/decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/polling/_poller.py:245\u001b[0m, in \u001b[0;36mLROPoller.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 245\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;66;03m# Let's handle possible None in forgiveness here\u001b[39;00m\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# https://github.com/python/mypy/issues/8165\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {},
      "id": "801c6bc2-467c-4418-aa7e-ef89a1e20e1c"
    },
    {
      "cell_type": "code",
      "source": [
        "print(book,\"\\n\",\"chunk text:\",book_map[random.randint(10, 50)][2][:80],\"...\\n\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713623789122
        }
      },
      "id": "97f9c5bb-c44b-4a4d-9780-591f9f8d128a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "As demonstrated above, Azure Document Intelligence proves to be superior to pyPDF. **For production scenarios, we strongly recommend using Azure Document Intelligence consistently**. When doing so, it's important to make a wise choice between the available models, such as \"prebuilt-document,\" \"prebuilt-layout,\" or others. You can find more information on model selection [HERE](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/choose-model-feature?view=doc-intel-3.0.0).\n"
      ],
      "metadata": {},
      "id": "9c279dfb-4fed-41b8-89e1-0ca2cefbcdc9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Vector-based index\n",
        "\n",
        "\n",
        "Now that we have the content of the book's chunks (each page of each book) in the dictionary `book_pages_map`, let's create the Vector index in our Azure Search Engine where this content is going to land"
      ],
      "metadata": {},
      "id": "7f5f9b7d-99e6-426d-a47e-343c7e8b492e"
    },
    {
      "cell_type": "code",
      "source": [
        "book_index_name = \"cogsrch-index-books\""
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1713769548685
        }
      },
      "id": "7d46e7c5-49c4-40f3-bb2d-79a9afeab4b1"
    },
    {
      "cell_type": "code",
      "source": [
        "### Create Azure Search Vector-based Index\n",
        "# Setup the Payloads header\n",
        "headers = {'Content-Type': 'application/json','api-key': os.environ['AZURE_SEARCH_KEY']}\n",
        "params = {'api-version': os.environ['AZURE_SEARCH_API_VERSION']}"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1713769551395
        }
      },
      "id": "1b07e84b-d306-4bc9-9124-e64f252dd7b2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Please note the following points regarding the index:\n",
        "\n",
        "- The ParentKey field is absent.\n",
        "- The page_num field is present.\n",
        "\n",
        "The absence of the ParentKey field is due to the utilization of a PUSH method, rather than a PULL method. This approach indicates that we are not leveraging the integrated indexing provided by the Azure AI Search engine. Instead, we are engaging in the process of parsing, performing OCR, and manually creating and pushing the content along with its vectors.\n",
        "\n",
        "This manual parsing process involves the use of either, the pyPDF library, or the Azure Document Intelligence API. These APIs allow for the segmentation of content by page rather than by a specified number of characters, which is the method employed by the Azure AI search indexer. Consequently, this enables the inclusion of page_num as a field in our index."
      ],
      "metadata": {},
      "id": "2faab899-977b-40d0-b36e-26f75ac07e54"
    },
    {
      "cell_type": "markdown",
      "source": [
        "REST API version 2023-10-01-Preview supports external and internal vectorization. This Notebook assumes an external vectorization strategy. This API also supports:\n",
        "    \n",
        "- vectorSearch algorithms, hnsw and exhaustiveKnn nearest neighbors, with parameters for indexing and scoring.\n",
        "- vectorProfiles for multiple combinations of algorithm configurations.\n",
        "\n",
        "Vector search algorithms include **exhaustive k-nearest neighbors (KNN)** and **Hierarchical Navigable Small World (HNSW)**. Exhaustive KNN performs a brute-force search that scans the entire vector space. HNSW performs an approximate nearest neighbor (ANN) search. While KNN provides exact nearest neighbor search results with high accuracy, its computational cost and poor scalability make it impractical for large datasets or real-time applications. HNSW, on the other hand, offers a highly efficient and scalable solution for nearest neighbor searches by finding approximate nearest neighbors quickly, making it more suitable for large-scale and high-dimensional data applications.\n",
        "\n",
        "\n",
        "check [HERE](https://learn.microsoft.com/en-us/azure/search/vector-search-how-to-create-index?tabs=config-2023-10-01-Preview%2Crest-2023-11-01%2Cpush%2Cportal-check-index) for the details of the vector configuration."
      ],
      "metadata": {},
      "id": "75d63e68-69a5-4b3b-8eb0-86da02cb7230"
    },
    {
      "cell_type": "code",
      "source": [
        "index_payload = {\n",
        "    \"name\": book_index_name,\n",
        "    \"vectorSearch\": {\n",
        "        \"algorithms\": [  # We are showing here 3 types of search algorithms configurations that you can do\n",
        "             {\n",
        "                 \"name\": \"my-hnsw-config-1\",\n",
        "                 \"kind\": \"hnsw\",\n",
        "                 \"hnswParameters\": {\n",
        "                     \"m\": 4,\n",
        "                     \"efConstruction\": 400,\n",
        "                     \"efSearch\": 500,\n",
        "                     \"metric\": \"cosine\"\n",
        "                 }\n",
        "             },\n",
        "             {\n",
        "                 \"name\": \"my-hnsw-config-2\",\n",
        "                 \"kind\": \"hnsw\",\n",
        "                 \"hnswParameters\": {\n",
        "                     \"m\": 8,\n",
        "                     \"efConstruction\": 800,\n",
        "                     \"efSearch\": 800,\n",
        "                     \"metric\": \"cosine\"\n",
        "                 }\n",
        "             },\n",
        "             {\n",
        "                 \"name\": \"my-eknn-config\",\n",
        "                 \"kind\": \"exhaustiveKnn\",\n",
        "                 \"exhaustiveKnnParameters\": {\n",
        "                     \"metric\": \"cosine\"\n",
        "                 }\n",
        "             }\n",
        "        ],\n",
        "        \"vectorizers\": [\n",
        "            {\n",
        "                \"name\": \"openai\",\n",
        "                \"kind\": \"azureOpenAI\",\n",
        "                \"azureOpenAIParameters\":\n",
        "                {\n",
        "                    \"resourceUri\" : os.environ['AZURE_OPENAI_ENDPOINT'],\n",
        "                    \"apiKey\" : os.environ['AZURE_OPENAI_API_KEY'],\n",
        "                    \"deploymentId\" : os.environ['EMBEDDING_DEPLOYMENT_NAME']\n",
        "                }\n",
        "            }\n",
        "        ],\n",
        "        \"profiles\": [  # profiles is the diferent kind of combinations of algos and vectorizers\n",
        "            {\n",
        "             \"name\": \"my-vector-profile-1\",\n",
        "             \"algorithm\": \"my-hnsw-config-1\",\n",
        "             \"vectorizer\":\"openai\"\n",
        "            },\n",
        "            {\n",
        "             \"name\": \"my-vector-profile-2\",\n",
        "             \"algorithm\": \"my-hnsw-config-2\",\n",
        "             \"vectorizer\":\"openai\"\n",
        "            },\n",
        "            {\n",
        "             \"name\": \"my-vector-profile-3\",\n",
        "             \"algorithm\": \"my-eknn-config\",\n",
        "             \"vectorizer\":\"openai\"\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "    \"semantic\": {\n",
        "        \"configurations\": [\n",
        "            {\n",
        "                \"name\": \"my-semantic-config\",\n",
        "                \"prioritizedFields\": {\n",
        "                    \"titleField\": {\n",
        "                        \"fieldName\": \"title\"\n",
        "                    },\n",
        "                    \"prioritizedContentFields\": [\n",
        "                        {\n",
        "                            \"fieldName\": \"chunk\"\n",
        "                        }\n",
        "                    ],\n",
        "                    \"prioritizedKeywordsFields\": []\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "    \"fields\": [\n",
        "        {\"name\": \"id\", \"type\": \"Edm.String\", \"key\": \"true\", \"filterable\": \"true\" },\n",
        "        {\"name\": \"title\",\"type\": \"Edm.String\",\"searchable\": \"true\",\"retrievable\": \"true\"},\n",
        "        {\"name\": \"chunk\",\"type\": \"Edm.String\",\"searchable\": \"true\",\"retrievable\": \"true\"},\n",
        "        {\"name\": \"name\", \"type\": \"Edm.String\", \"searchable\": \"true\", \"retrievable\": \"true\", \"sortable\": \"false\", \"filterable\": \"false\", \"facetable\": \"false\"},\n",
        "        {\"name\": \"location\", \"type\": \"Edm.String\", \"searchable\": \"false\", \"retrievable\": \"true\", \"sortable\": \"false\", \"filterable\": \"false\", \"facetable\": \"false\"},\n",
        "        {\"name\": \"page_num\",\"type\": \"Edm.Int32\",\"searchable\": \"false\",\"retrievable\": \"true\"},\n",
        "        {\n",
        "            \"name\": \"chunkVector\",\n",
        "            \"type\": \"Collection(Edm.Single)\",\n",
        "            \"dimensions\": 1536,\n",
        "            \"vectorSearchProfile\": \"my-vector-profile-3\", # we picked profile 3 to show that this index uses eKNN vs HNSW (on prior notebooks)\n",
        "            \"searchable\": \"true\",\n",
        "            \"retrievable\": \"true\",\n",
        "            \"filterable\": \"false\",\n",
        "            \"sortable\": \"false\",\n",
        "            \"facetable\": \"false\"\n",
        "        }\n",
        "        \n",
        "    ],\n",
        "}\n",
        "\n",
        "r = requests.put(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + book_index_name,\n",
        "                 data=json.dumps(index_payload), headers=headers, params=params)\n",
        "print(r.status_code)\n",
        "print(r.ok)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "204\nTrue\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1713769555136
        }
      },
      "id": "2df4db6b-969b-4b91-963f-9334e17a4e3c"
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment to debug errors\n",
        "# r.text"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713623829521
        }
      },
      "id": "36691ff0-c4c8-49d0-bfa8-3e076ece0ce5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload the Document chunks and its vectors to the Index"
      ],
      "metadata": {},
      "id": "3bc7dda9-4725-410e-9465-54f0298fc758"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code will iterate over each chunk of each book and use the Azure Search Rest API upload method to insert each document with its corresponding vector (using OpenAI embedding model) to the index."
      ],
      "metadata": {},
      "id": "d73e7600-7902-48d4-b199-9d9dc0a17aa0"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for bookname,bookmap in book_pages_map.items():\n",
        "    print(\"Uploading chunks from\",bookname)\n",
        "    for page in tqdm(bookmap):\n",
        "        try:\n",
        "            page_num = page[0] + 1\n",
        "            content = page[2]\n",
        "            book_url = BASE_CONTAINER_URL + bookname\n",
        "            upload_payload = {\n",
        "                \"value\": [\n",
        "                    {\n",
        "                        \"id\": text_to_base64(bookname + str(page_num)),\n",
        "                        \"title\": f\"{bookname}_page_{str(page_num)}\",\n",
        "                        \"chunk\": content,\n",
        "                        \"chunkVector\": embedder.embed_query(content if content!=\"\" else \"-------\"),\n",
        "                        \"name\": bookname,\n",
        "                        \"location\": book_url,\n",
        "                        \"page_num\": page_num,\n",
        "                        \"@search.action\": \"upload\"\n",
        "                    },\n",
        "                ]\n",
        "            }\n",
        "\n",
        "            r = requests.post(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + book_index_name + \"/docs/index\",\n",
        "                                 data=json.dumps(upload_payload), headers=headers, params=params)\n",
        "            if r.status_code != 200:\n",
        "                print(r.status_code)\n",
        "                print(r.text)\n",
        "        except Exception as e:\n",
        "            print(\"Exception:\",e)\n",
        "            print(content)\n",
        "            continue"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Uploading chunks from azure-ai-studio.pdf\nUploading chunks from azure-ai-services.pdf\nCPU times: user 1min 27s, sys: 2.75 s, total: 1min 30s\nWall time: 6min 11s\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|██████████| 654/654 [04:30<00:00,  2.42it/s]\n100%|██████████| 290/290 [01:41<00:00,  2.86it/s]\n"
        }
      ],
      "execution_count": 12,
      "metadata": {},
      "id": "f5c8aa55-1b60-4057-93db-0d4a89993a57"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Query the Index"
      ],
      "metadata": {},
      "id": "715cddcf-af7b-4006-a047-853fc7a66be3"
    },
    {
      "cell_type": "code",
      "source": [
        "#QUESTION = \"What's Azure AI Search?\"\n",
        "QUESTION = \"Can I move, backup, and restore indexes?\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713623927099
        }
      },
      "id": "8b408798-5527-44ca-9dba-cad2ee726aca"
    },
    {
      "cell_type": "code",
      "source": [
        "indexes = [book_index_name]\n",
        "k=10 # in this index k corresponds to the top pages as well"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713623928701
        }
      },
      "id": "1b182ade-0ddd-47a1-b1eb-2cbf435c317f"
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = CustomAzureSearchRetriever(indexes=[book_index_name], topK=k, reranker_threshold=1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713623929721
        }
      },
      "id": "d50eecb2-ce26-4127-a62b-79735b937046"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: that we are picking a larger k=20 since these chunks are NOT of 5000 chars each like prior notebooks, but instead each page is a chunk."
      ],
      "metadata": {},
      "id": "fdd2f3f2-2d66-4bd4-b90b-d30970b71af4"
    },
    {
      "cell_type": "code",
      "source": [
        "COMPLETION_TOKENS = 2500\n",
        "llm = AzureChatOpenAI(deployment_name=os.environ[\"GPT35_DEPLOYMENT_NAME\"], temperature=0.5, max_tokens=COMPLETION_TOKENS).configurable_alternatives(\n",
        "    ConfigurableField(id=\"model\"),\n",
        "    default_key=\"gpt35\",\n",
        "    gpt4=AzureChatOpenAI(deployment_name=os.environ[\"GPT4_DEPLOYMENT_NAME\"], temperature=0, max_tokens=COMPLETION_TOKENS),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713623931387
        }
      },
      "id": "410ff796-dab1-4817-a3a5-82eeff6c0c57"
    },
    {
      "cell_type": "code",
      "source": [
        "In `utils.py` we created the **CustomAzureSearchRetriever** class that we will use going forward"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "c33c2851-08c5-4e7c-ba7b-4655a6021e1e"
    },
    {
      "cell_type": "code",
      "source": [
        "chain = (\n",
        "    {\n",
        "        \"context\": itemgetter(\"question\") | retriever, # Passes the question to the retriever and the results are assign to context\n",
        "        \"question\": itemgetter(\"question\")\n",
        "    }\n",
        "    | DOCSEARCH_PROMPT  # Passes the 4 variables above to the prompt template\n",
        "    | llm   # Passes the finished prompt to the LLM\n",
        "    | StrOutputParser()  # converts the output (Runnable object) to the desired output (string)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "26f47c69-44d8-48e3-974e-7989b4a8b7c5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### With GPT 3.5"
      ],
      "metadata": {},
      "id": "765df250-af7f-46c9-8d7a-15c0522969ec"
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in chain.with_config(configurable={\"model\": \"gpt35\"}).stream({\"question\": QUESTION}):\n",
        "    print(chunk, end=\"\", flush=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713623789372
        }
      },
      "id": "73f34192-519d-45b9-a0e2-a8b2de51ee1e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### With GPT 4"
      ],
      "metadata": {},
      "id": "d4a8761d-2c1e-4369-b7c4-c3571a0793e9"
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in chain.with_config(configurable={\"model\": \"gpt4\"}).stream(\n",
        "    {\"question\": QUESTION, \"language\": \"English\"}):\n",
        "    print(chunk, end=\"\", flush=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713623789394
        }
      },
      "id": "14b77511-b178-4c9b-9fa5-fdddb0d3e586"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "\n",
        "In this notebook we learned how to deal with complex and large Documents and make them available for Q&A over them using [Hybrid Search](https://learn.microsoft.com/en-us/azure/search/search-get-started-vector#hybrid-search) (text + vector search).\n",
        "\n",
        "We also learned the power of Azure Document Inteligence API and why it is recommended for production scenarios where manual Document parsing (instead of Azure Search Indexer Document Cracking) is necessary.\n",
        "\n",
        "Using Azure AI Search with its Vector capabilities and hybrid search features eliminates the need for other vector databases such as Weaviate, Qdrant, Milvus, Pinecone, and so on.\n"
      ],
      "metadata": {},
      "id": "3941796c-7655-4888-a358-8a62e380bd7e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NEXT\n",
        "So far we have learned how to use OpenAI vectors and completion APIs in order to get an excelent answer from our documents stored in Azure AI Search. This is the backbone for <font color=\"red\">a GPT Smart Search Engine.</font>\n",
        "\n",
        "However, we are missing something: **How to have a conversation with this engine?**\n",
        "\n",
        "On the next Notebook, we are going to understand the concept of **memory**. This is necessary in order to have a chatbot that can establish a conversation with the user. Without memory, there is no real conversation."
      ],
      "metadata": {},
      "id": "85d9a7d1-f029-416b-8eb2-00a8afb9151d"
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}